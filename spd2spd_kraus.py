# script to build a deep kraus decomposition model for SPD to SPD matrices mapping
# train and evaluate on toy data generated by make_data.sh

from __future__ import print_function

import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' 

import keras
from keras.models import Sequential
from keras import backend as K
from keras.layers import Activation, Dropout, BatchNormalization
from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau
from KrausLayer import KrausLayer
from PSDReluLayer import PSDReluLayer
import numpy as np
import sys

batch_size = 16
epochs = 200

context = '10000_100_40_20'

try:
  context = str(sys.argv[1])
  fold = int(sys.argv[2])
except:
  fold = 0
  print('usage: '+sys.argv[0]+' <context> <fold> <rank> <depth> <intermediate_dims>')
  print('default: rank = 10; depth = 1 ; intermediate_dims = 15')
  sys.exit(0)

context2 = context + '_' + str(fold)

try:
  rank = int(sys.argv[3])
except:
  rank = 10

try:
  depth = int(sys.argv[4])
  intermediate_dims = int(sys.argv[5])
except:
  depth = 1
  intermediate_dims = -1

try:
  nl = int(sys.argv[6]) # non linearity ?
except:
  nl = 0

def reset_weights(model):
    session = K.get_session()
    for layer in model.layers: 
        if isinstance(layer, keras.engine.network.Network):
            reset_weights(layer)
            continue
        for v in layer.__dict__.values():
            if hasattr(v, 'initializer'):
                v.initializer.run(session=session)

# load the data, generated by toy_experiments.py
X = np.load('data/spd2spd/X_'+context2+'.npy')
Y = np.load('data/spd2spd/Y_'+context2+'.npy')
Xt = np.load('data/spd2spd/Xt_'+context2+'.npy')
Yt = np.load('data/spd2spd/Yt_'+context2+'.npy')

input_shape = X[0].shape

# build model
model = Sequential()
for d in range(depth):
    dims = intermediate_dims
    if d == depth - 1: dims = Y[0].shape[0]
    if d == 0: model.add(KrausLayer(dims, rank, input_shape=input_shape))
    else: model.add(KrausLayer(dims, rank))
    if nl > 0 and d < depth - 1: model.add(PSDReluLayer(0.1))
print(model.summary())
model.compile(loss=keras.losses.mse, optimizer=keras.optimizers.Adam(0.001))

# train and evaluate
scores = []
for i in range(5):
    reset_weights(model)
    loss = model.fit(X, Y, batch_size=batch_size, epochs=epochs, verbose=1)
    mse = model.evaluate(Xt, Yt, verbose=0)
    scores.append(mse)
    print("mse = ", mse, "iter = ", i)
    
f = open('results_spd2spd/'+str(context)+'_'+str(fold)+'_'+str(rank)+'_'+str(depth)+'_'+str(intermediate_dims)+'_'+str(nl)+'.out', 'w')
f.write('Train loss: '+ str(loss.history['loss'][-1])+ ' Test loss: '+ str(np.mean(scores))+' '+ str(np.std(scores))+ ' context: '+ str(context)+' '+ str(fold)+ ' rank: '+ str(rank)+ ' depth: '+ str(depth)+ ' intermediate_dims: '+ str(intermediate_dims)+ ' nl '+ str(nl)+ ' nb_params '+ str(model.count_params()) + '\n')
f.close()
